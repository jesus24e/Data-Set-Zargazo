{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "988687fd",
   "metadata": {},
   "source": [
    "# ðŸ“¦ InstalaciÃ³n de LibrerÃ­as Necesarias para el Proyecto\n",
    "\n",
    "Este proyecto requiere varias bibliotecas para el anÃ¡lisis y procesamiento de datos e imÃ¡genes. A continuaciÃ³n, se listan y describen:\n",
    "\n",
    "- **pandas**: ManipulaciÃ³n y anÃ¡lisis de datos estructurados (tablas tipo DataFrame).\n",
    "- **numpy**: Operaciones matemÃ¡ticas avanzadas y manejo de arreglos multidimensionales.\n",
    "- **matplotlib**: VisualizaciÃ³n bÃ¡sica de grÃ¡ficos e imÃ¡genes.\n",
    "- **seaborn**: VisualizaciÃ³n estadÃ­stica avanzada basada en matplotlib.\n",
    "- **opencv-python (cv2)**: Procesamiento de imÃ¡genes y visiÃ³n por computadora.\n",
    "- **scikit-image**: Lectura, filtrado y anÃ¡lisis de imÃ¡genes.\n",
    "- **plotly**: VisualizaciÃ³n interactiva y dinÃ¡mica de grÃ¡ficos.\n",
    "- **kaggle**: Interfaz para descargar datasets desde [Kaggle.com](https://www.kaggle.com).\n",
    "\n",
    "### â± Tiempo estimado de instalaciÃ³n:\n",
    "- ConexiÃ³n buena: 3 a 7 minutos.\n",
    "- ConexiÃ³n lenta o Colab reciÃ©n iniciado: 10 a 15 minutos.\n",
    "\n",
    "### ðŸ’¡ RecomendaciÃ³n:\n",
    "- Si no va a trabajar directamente con imÃ¡genes, puede comentar o eliminar las siguientes librerÃ­as:\n",
    "  - `opencv-python`\n",
    "  - `scikit-image`\n",
    "\n",
    "### âš ï¸ Importante:\n",
    "- La librerÃ­a `kaggle` es necesaria solo si va a descargar datasets directamente desde Kaggle.\n",
    "- AsegÃºrese de haber subido el archivo `kaggle.json` al entorno antes de autenticar con `KaggleApi`.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e96296",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "!pip install -q kaggle\n",
    "!pip install pandas\n",
    "!pip install numpy\n",
    "!pip install matplotlib\n",
    "!pip install seaborn\n",
    "!pip install opencv-python\n",
    "!pip install scikit-image\n",
    "!pip install plotly\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601213dc",
   "metadata": {},
   "source": [
    "### ðŸ“¥ ImportaciÃ³n de librerÃ­as necesarias\n",
    "\n",
    "Este bloque importa todas las librerÃ­as esenciales que se usarÃ¡n a lo largo del proyecto. **Puede tardar alrededor de un minuto** en completarse, dependiendo del entorno y los recursos de tu mÃ¡quina, ya que algunas son pesadas.\n",
    "\n",
    "A continuaciÃ³n se explica el propÃ³sito de cada librerÃ­a:\n",
    "\n",
    "- **`os`**  \n",
    "  Permite interactuar con el sistema operativo. AquÃ­ se usa para cambiar la ubicaciÃ³n en la que `kaggle.json` serÃ¡ buscado (en este caso, la raÃ­z del proyecto).\n",
    "\n",
    "- **`kaggle.api.kaggle_api_extended.KaggleApi`**  \n",
    "  Se utiliza para autenticar y descargar datasets directamente desde [Kaggle](https://www.kaggle.com).\n",
    "\n",
    "- **`pandas` (`pd`)**  \n",
    "  Manejo y anÃ¡lisis de datos en estructuras tipo tabla (`DataFrame`).\n",
    "\n",
    "- **`numpy` (`np`)**  \n",
    "  CÃ¡lculo numÃ©rico y manejo eficiente de arreglos multidimensionales.\n",
    "\n",
    "- **`shutil`**  \n",
    "  Permite copiar, mover o eliminar archivos y carpetas; Ãºtil para organizar las imÃ¡genes.\n",
    "\n",
    "- **`cv2` (OpenCV)**  \n",
    "  LibrerÃ­a de visiÃ³n por computadora para leer, modificar y procesar imÃ¡genes.\n",
    "\n",
    "- **`matplotlib.pyplot` (`plt`)**  \n",
    "  VisualizaciÃ³n de datos mediante grÃ¡ficos estÃ¡ticos y personalizables.\n",
    "\n",
    "- **`seaborn` (`sns`)**  \n",
    "  Complemento de `matplotlib` para grÃ¡ficos estadÃ­sticos mÃ¡s atractivos y fÃ¡ciles de generar.\n",
    "\n",
    "- **`plotly.graph_objs` (`go`)**  \n",
    "  GeneraciÃ³n de grÃ¡ficos interactivos (por ejemplo, lÃ­neas, barras, mapas de calor).\n",
    "\n",
    "- **`skimage.io`**  \n",
    "  Lectura y escritura de imÃ¡genes desde archivos o URLs, Ãºtil para visualizaciÃ³n y anÃ¡lisis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe6ad4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['KAGGLE_CONFIG_DIR'] = os.getcwd()#cambio de la ubicacion de busqueda de el kaggle.json para buscarlo en la raiz del proyecto\n",
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import shutil \n",
    "import cv2 \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from plotly import graph_objs as go\n",
    "from skimage import io\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee45a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "directorio = \"zargazo_dataset\"\n",
    "\n",
    "# Verifica si existe la carpeta para el data set del zargazo, si no la crea\n",
    "if not os.path.exists(directorio):\n",
    "    os.makedirs(directorio)\n",
    "    print(f\"âœ… Carpeta creada: {directorio}\")\n",
    "else:\n",
    "    print(f\"â„¹ï¸ La carpeta ya existe: {directorio}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b5ab3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#verifica si el data set ya fue descargado\n",
    "if os.path.exists(directorio) and len(os.listdir(directorio)) > 0:\n",
    "    print(f\"âœ… Dataset ya descargado en ./{directorio}.\")\n",
    "else:\n",
    "    print(\"ðŸ“¥ Dataset no encontrado, descargando...\")\n",
    "    api = KaggleApi()\n",
    "    api.authenticate()\n",
    "    api.dataset_download_files(\"sergiogiles/sargacerosds\", path=directorio, unzip=True)\n",
    "    print(f\"âœ… Dataset descargado en ./{directorio}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827baeb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ruta_labels = os.path.join(directorio, \"labels\", \"labels.csv\")\n",
    "df_train = pd.read_csv(ruta_labels)\n",
    "datos = df_train.iloc[:,:] # Seleccionar un subconjunto\n",
    "bd_lenght, bd_width = datos.shape\n",
    "datos.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5aa57c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imprimir cuales son las etiquetas Ãºnicas\n",
    "print(datos.label.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460791bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "datos.info()\n",
    "print('Tipo de datos de las etiquetas: ', type(datos['label'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6368797",
   "metadata": {},
   "outputs": [],
   "source": [
    "datos.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71dbcfc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#graficos de distriibucion de nivel de sargazo\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "sns.countplot(x='label',data=datos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6896bbd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#graficos de distribucion de las etiquetas de las fotos\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "sns.countplot(x='scene',data=datos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16af039",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ImÃ¡genes de ejemplo\n",
    "\n",
    "import random\n",
    "\n",
    "idx = random.randint(1, bd_lenght)\n",
    "imagen_ejemplo=io.imread(directorio +\"/images/\"+ str(datos.image_name.iloc[idx]))\n",
    "\n",
    "plt.title(\"Sample image, class=\" + str(datos.label.iloc[idx]))\n",
    "plt.imshow(imagen_ejemplo,vmin=0,vmax=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209778ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para obtener informaciÃ³n de la imagen podemos utilizar dtype y shape \n",
    "print('La imagen es de tipo:', imagen_ejemplo.dtype)\n",
    "print(\"Dimensiones de la imagen (high, width, channels):\", imagen_ejemplo.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb0af42",
   "metadata": {},
   "source": [
    "codigo de la red neuronal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7720529c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import io, transform\n",
    "from PIL import Image\n",
    "import time\n",
    "import copy\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torch.autograd import Variable\n",
    "from torchvision import datasets, models, transforms, utils\n",
    "import torch.optim as optim\n",
    "import sklearn\n",
    "import sklearn.model_selection as skl\n",
    "import seaborn as sn\n",
    "%matplotlib inline\n",
    "use_gpu = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Assume that we are on a CUDA machine, then this should print a CUDA device:\n",
    "print(device)\n",
    "print(\"Torch version: \", torch.__version__)\n",
    "print(\"Torchvision version: \", torchvision.__version__)\n",
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8a8d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directorio de la carpeta donde esta el dataset\n",
    "#img_folder = '/kaggle/input/publicsargazods/images'\n",
    "img_folder = os.path.join(\"zargazo_dataset\",\"images\")\n",
    "#csv_file = '/kaggle/input/publicsargazods/labels/labels.csv'\n",
    "csv_file = os.path.join(\"zargazo_dataset\", \"labels\", \"labels.csv\")\n",
    "\n",
    "# Hyper parameters\n",
    "epochs = 5\n",
    "current_epoch = 0\n",
    "batch_size = 32\n",
    "learning_rate = 0.001\n",
    "run_training = True #Si deseamos que el notebook ejecute el entrenamiento\n",
    "model_name = 'resnet' # Red a cargar\n",
    "pretrained = True # True indica que la red se va a inicializar con los parÃ¡metros entrenados\n",
    "feature_extract = False #True indica que no se actualizan los parÃ¡metros\n",
    "save_weights = True\n",
    "\n",
    "wts_str = 'w_' + model_name + '_pret_' + str(pretrained) + '_feat_' + str(feature_extract) + '_lr_'+ str(learning_rate) \n",
    "print(wts_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc3d501",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SargazoDataset(Dataset):\n",
    "    def __init__(self, dataframe, images_path, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            txt_frame_file (string): Path to the txt files with labels.\n",
    "            images_path (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.sargazo_frame = dataframe\n",
    "        self.root_dir = images_path\n",
    "        self.transform = transform\n",
    "        self.class2id = test_count = {'nada': 0, 'bajo': 1, 'moderado': 2, 'abundante': 3, 'excesivo': 4}\n",
    "        \n",
    "    def pil_loader(self, path):\n",
    "        with open(path, 'rb') as f:\n",
    "            img = Image.open(f)\n",
    "            return img.convert('RGB')\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.sargazo_frame)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        # cuidado si cambia la tabla se debe de cambiar esto\n",
    "        image_path = os.path.join(self.root_dir, self.sargazo_frame.iloc[idx, 0])\n",
    "        \n",
    "        image = self.pil_loader(image_path)\n",
    "        \n",
    "        try: \n",
    "            label = self.sargazo_frame.iloc[idx, 3]\n",
    "        except:\n",
    "            label = 'unknown'\n",
    "\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        sample = (image, self.class2id[label])\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e1152f8",
   "metadata": {},
   "source": [
    "division del conjunto de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba1baeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class2id = test_count = {'nada': 0, 'bajo': 1, 'moderado': 2, 'abundante': 3, 'excesivo': 4}\n",
    "id2class = {0: 'nada', 1: 'bajo', 2: 'moderado', 3: 'abundante', 4: 'excesivo'}\n",
    "num_classes = len(id2class)\n",
    "\n",
    "full_dataset = pd.read_csv(csv_file) \n",
    "full_dataset.sample(5)\n",
    "\n",
    "#print(full_dataset.iloc[0, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e8aec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_labels = 'label'\n",
    "random = 46 # for reproducible experiments\n",
    "\n",
    "# Aqui se divide el conjunto de datos\n",
    "train_df, valid_df = skl.train_test_split(full_dataset, test_size = 0.2, stratify = full_dataset[col_labels], random_state = random)\n",
    "\n",
    "training_dataset = SargazoDataset(train_df, img_folder)\n",
    "test_dataset = SargazoDataset(valid_df, img_folder)\n",
    "\n",
    "print(\"NÃºmero de ejemplos:\", len(training_dataset))\n",
    "\n",
    "def show_image(image, label):\n",
    "    plt.imshow(image, cmap = 'gray')\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc06d0e8",
   "metadata": {},
   "source": [
    "mostrar ejemplos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dafc1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "\n",
    "for i in range(len(training_dataset)):\n",
    "    sample = training_dataset[i]\n",
    "    print(sample)\n",
    "    image, label = sample\n",
    "    \n",
    "    ax = plt.subplot(1, 4, i + 1)\n",
    "    plt.tight_layout()\n",
    "    ax.set_title('Sample #{} Class {}'.format(i, id2class[label]))\n",
    "    ax.axis('off')\n",
    "    show_image(image, label)\n",
    "\n",
    "    if i == 3:\n",
    "        plt.show()\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a02b7c9",
   "metadata": {},
   "source": [
    "descenso por gradiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b866c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloaders, criterion, optimizer, num_epochs = 25, is_inception= False, save_after = 100):\n",
    "    since = time.time()\n",
    "    \n",
    "    val_acc_history = []\n",
    "    train_acc_history = []\n",
    "    val_loss_history = []\n",
    "    train_loss_history = []\n",
    "    \n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    \n",
    "    #print(device)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs -1))\n",
    "        \n",
    "        #Each epoch as a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            \n",
    "            # Iterate over data\n",
    "            for inputs, labels in iter(dataloaders[phase]):\n",
    "                #print(inputs)\n",
    "                #print(labels)\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                \n",
    "                #zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                #forward\n",
    "                # track history\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    \n",
    "                    if is_inception and phase == 'train':\n",
    "                        outputs, aux_outputs = model(inputs)\n",
    "                        loss1 = criterion(outputs, labels)\n",
    "                        loss2 = criterion(aux_outputs, labels)\n",
    "                        loss = loss1 + 0.4*loss2\n",
    "                        \n",
    "                    else:\n",
    "                        outputs = model(inputs)\n",
    "                        loss = criterion(outputs, labels)\n",
    "                        \n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    \n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                #statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "                \n",
    "            epoch_loss = running_loss /len(dataloaders[phase].dataset)\n",
    "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
    "            \n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "            \n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                torch.save(model.state_dict(), wts_str + '_best.pt')\n",
    "            if phase == 'val':\n",
    "                val_acc_history.append(epoch_acc)\n",
    "                val_loss_history.append(epoch_loss)\n",
    "            else:\n",
    "                train_acc_history.append(epoch_acc)\n",
    "                train_loss_history.append(epoch_loss)\n",
    "            \n",
    "            if phase == 'train' and epoch % save_after == 0 :\n",
    "                torch.save(model.state_dict(), wts_str + '_epoch' + str(epoch) + '.pt')\n",
    "        print()\n",
    "        \n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:.4f}'.format(best_acc))\n",
    "    \n",
    "    #load the best model\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, val_acc_history, train_acc_history, val_loss_history, train_loss_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8acb0cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set model parameters\n",
    "def set_parameter_requires_grad(model, feature_extracting):\n",
    "    if feature_extracting:\n",
    "        for param in model.parameters():\n",
    "            # Freeze parameters\n",
    "            param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea54a02",
   "metadata": {},
   "source": [
    "crear modelo de red neuronal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3dfd04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and reshape the networks\n",
    "def initialize_model(model_name, num_classes, feature_extract, use_pretrained=True):\n",
    "    # Initialize these variables which will be set in this if statement. Each of these\n",
    "    #   variables is model specific.\n",
    "    model_ft = None\n",
    "    input_size = 0\n",
    "\n",
    "    if model_name == \"resnet\":\n",
    "        \"\"\" Resnet18\n",
    "        \"\"\"\n",
    "        model_ft = models.resnet18(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"alexnet\":\n",
    "        \"\"\" Alexnet\n",
    "        \"\"\"\n",
    "        model_ft = models.alexnet(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier[6].in_features\n",
    "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"vgg\":\n",
    "        \"\"\" VGG16\n",
    "        \"\"\"\n",
    "        model_ft = models.vgg16(pretrained=use_pretrained)\n",
    "        #model_ft = models.vgg16(weights='IMAGENET1K_V1')\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier[6].in_features\n",
    "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"squeezenet\":\n",
    "        \"\"\" Squeezenet\n",
    "        \"\"\"\n",
    "        model_ft = models.squeezenet1_0(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        model_ft.classifier[1] = nn.Conv2d(512, num_classes, kernel_size=(1,1), stride=(1,1))\n",
    "        model_ft.num_classes = num_classes\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"densenet\":\n",
    "        \"\"\" Densenet\n",
    "        \"\"\"\n",
    "        model_ft = models.densenet121(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier.in_features\n",
    "        model_ft.classifier = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"inception\":\n",
    "        \"\"\" Inception v3\n",
    "        Be careful, expects (299,299) sized images and has auxiliary output\n",
    "        \"\"\"\n",
    "        model_ft = models.inception_v3(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        # Handle the auxilary net\n",
    "        num_ftrs = model_ft.AuxLogits.fc.in_features\n",
    "        model_ft.AuxLogits.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        # Handle the primary net\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 299\n",
    "\n",
    "    else:\n",
    "        print(\"Invalid model name, exiting...\")\n",
    "        exit()\n",
    "\n",
    "    return model_ft, input_size\n",
    "\n",
    "# Initialize the model for this run\n",
    "model_ft, input_size = initialize_model(model_name, num_classes, feature_extract, use_pretrained=pretrained)\n",
    "\n",
    "# Print the model we just instantiated\n",
    "print(model_ft)\n",
    "\n",
    "model_ft.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d6a3a4",
   "metadata": {},
   "source": [
    "empieza el entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6271a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation and normalization for training\n",
    "# Just normalization for validation\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(input_size),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(input_size),\n",
    "        transforms.CenterCrop(input_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e924bb16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# configure paths to the description txt file and the images folder\n",
    "#images_path = '../input/sargazo-dataset/sargazo_dataset/images'\n",
    "\n",
    "# Create training and validation datasets\n",
    "image_datasets = {'train': SargazoDataset(train_df, img_folder, data_transforms['train']), 'val': SargazoDataset(valid_df, img_folder, data_transforms['val'])}\n",
    "# Create training and validation dataloaders\n",
    "dataloaders_dict = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size, shuffle=True, num_workers=4) for x in ['train', 'val']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a579999",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the optimizer\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "params_to_update = model_ft.parameters()\n",
    "print(\"Params to learn\")\n",
    "\n",
    "if feature_extract:\n",
    "    params_to_update = []\n",
    "    for name, param in model_ft.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            params_to_update.append(param)\n",
    "            print(\"\\t\", name)\n",
    "else:\n",
    "    for name, param in model_ft.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            print(\"\\t\", name)\n",
    "            \n",
    "optimizer_ft = optim.SGD(params_to_update, lr=learning_rate,momentum=0.9)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00e8308",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute full training\n",
    "if run_training:\n",
    "    model_ft, hist, hist_t,loss_hist,loss_hist_t = train_model(model_ft, dataloaders_dict, criterion, optimizer_ft, num_epochs = epochs, is_inception=(model_name==\"inception\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d731fae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if save_weights:\n",
    "    torch.save(model_ft.state_dict(), wts_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd9b133",
   "metadata": {},
   "source": [
    "graficar resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100c5be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the training curves of validation accuracy vs. number\n",
    "#  of training epochs for the transfer learning method and\n",
    "#  the model trained from scratch\n",
    "vhist = []\n",
    "thist = []\n",
    "\n",
    "vhist = [h.cpu().numpy() for h in hist]\n",
    "thist = [h.cpu().numpy() for h in hist_t]\n",
    "#shist = [h.cpu().numpy() for h in scratch_hist]\n",
    "\n",
    "np.save('val_history', vhist)\n",
    "np.save('train_history', vhist)\n",
    "\n",
    "plt.title(\"Validation Accuracy vs. Number of Training Epochs\")\n",
    "plt.xlabel(\"Training Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.plot(range(1,epochs+1),thist,label=\"Training\")\n",
    "plt.plot(range(1,epochs+1),vhist,label=\"Validation\")\n",
    "plt.ylim((0,1.))\n",
    "plt.xticks(np.arange(1, epochs+1, 1.0))\n",
    "plt.legend()\n",
    "file_name = wts_str + '_acc.png'\n",
    "plt.savefig(file_name)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd62ab70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the training curves of validation accuracy vs. number\n",
    "#  of training epochs for the transfer learning method and\n",
    "#  the model trained from scratch\n",
    "vhist_loss = np.array(loss_hist)\n",
    "thist_loss = np.array(loss_hist_t)\n",
    "\n",
    "np.save('val_history', vhist_loss)\n",
    "np.save('train_history', thist_loss)\n",
    "\n",
    "plt.title(\"Validation Loss vs. Number of Training Epochs\")\n",
    "plt.xlabel(\"Training Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.plot(range(1,epochs+1),thist_loss,label=\"Training\")\n",
    "plt.plot(range(1,epochs+1),vhist_loss,label=\"Validation\")\n",
    "plt.ylim((0,4.))\n",
    "plt.xticks(np.arange(1, epochs+1, 1.0))\n",
    "plt.legend()\n",
    "file_name = wts_str + '_loss.png'\n",
    "plt.savefig(file_name)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3290c54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, dataloaders):\n",
    "    print(\"Evaluating model\")\n",
    "    print(time.time())\n",
    "            \n",
    "    # Iterate over data\n",
    "    it = 0\n",
    "    for inputs, labels in dataloaders['val']:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "                \n",
    "        model.train(False)\n",
    "        model.eval()\n",
    "                    \n",
    "        outputs = model(inputs)\n",
    "                        \n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        \n",
    "        np_pred_labels = preds.cpu().numpy()\n",
    "        np_real_labels = labels.cpu().numpy()\n",
    "        if it == 0:\n",
    "            pred_labels = np_pred_labels\n",
    "            real_labels = np_real_labels\n",
    "        else:\n",
    "            pred_labels = np.concatenate((pred_labels,np_pred_labels))\n",
    "            real_labels = np.concatenate((real_labels,np_real_labels))\n",
    "        it= it+1\n",
    "        \n",
    "        del inputs\n",
    "        del labels\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    print(time.time())\n",
    "    return pred_labels,real_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986ce074",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_labels,actual_labels = test_model(model_ft, dataloaders_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03db1df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(actual_labels,predict_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56efc15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_confusion = pd.crosstab(actual_labels, predict_labels,rownames=[\"True label\"],colnames=[\"Predicted label\"])\n",
    "print(df_confusion)\n",
    "df_confusion.rename(columns=id2class,index=id2class,inplace=True)\n",
    "print(df_confusion)\n",
    "df_confusion.to_csv('cm_exp5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe243fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(9,6))\n",
    "\n",
    "parameters = {'axes.labelsize': 10}\n",
    "plt.rcParams.update(parameters)\n",
    "\n",
    "g = sn.heatmap(df_confusion, annot = True, cmap = 'Blues',ax=ax)\n",
    "g.set_xticklabels(g.get_xticklabels(), rotation=45, horizontalalignment='right')\n",
    "g.set_yticklabels(g.get_yticklabels(), rotation=0, horizontalalignment='right')\n",
    "\n",
    "plt.savefig(\"CM_exp5.eps\",format = \"eps\",bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27b3967",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_norm_col= round(df_confusion.div(df_confusion.sum(axis=1),axis=0),2) \n",
    "print(df_norm_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aeedc2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(9,6))\n",
    "\n",
    "parameters = {'axes.labelsize': 10}\n",
    "plt.rcParams.update(parameters)\n",
    "\n",
    "g = sn.heatmap(df_norm_col, annot = True, cmap = 'Blues')\n",
    "g.set_xticklabels(g.get_xticklabels(), rotation=45, horizontalalignment='right')\n",
    "g.set_yticklabels(g.get_yticklabels(), rotation=0, horizontalalignment='right')\n",
    "\n",
    "plt.savefig(\"CM_exp5_norm.eps\",format = \"eps\",bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a67badc8",
   "metadata": {},
   "source": [
    "inferencia para el challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9aed5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_file = '/kaggle/input/publicsargazods/labels/test.csv'\n",
    "test_file = os.path.join(\"zargazo_dataset\", \"labels\", \"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aeed4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(test_file) \n",
    "test_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714acfdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pil_loader(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        img = Image.open(f)\n",
    "        return img.convert('RGB')\n",
    "\n",
    "    \n",
    "model_ft.eval()\n",
    "test_predictions = []\n",
    "for file in test_df['image_name']:\n",
    "    \n",
    "    # cuidado si cambia la tabla se debe de cambiar esto\n",
    "    image_path = os.path.join(img_folder, file)\n",
    "    #print(image_path)\n",
    "    \n",
    "    image = pil_loader(image_path)\n",
    "    img_transf = data_transforms['val'](image)\n",
    "    img_transf = img_transf.unsqueeze(0)\n",
    "    #print(img_transf.shape)\n",
    "    \n",
    "    #print(labels)\n",
    "    img_transf = img_transf.to(device)\n",
    "                       \n",
    "    outputs = model_ft(img_transf)\n",
    "    #print(outputs)                    \n",
    "    _, preds = torch.max(outputs, 1)\n",
    "    test_predictions.append(id2class[preds.cpu().numpy()[0]])\n",
    "    \n",
    "#print(test_predictions)\n",
    "temp = {'image_name': test_df['image_name'], 'label': test_predictions}\n",
    "output_df = pd.DataFrame(data=temp)\n",
    "output_df.sample(10)\n",
    "\n",
    "output_df.to_csv('outputs.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e13da7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
