{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "988687fd",
   "metadata": {},
   "source": [
    "# 📦 Instalación de Librerías Necesarias para el Proyecto\n",
    "\n",
    "Este proyecto requiere varias bibliotecas para el análisis y procesamiento de datos e imágenes. A continuación, se listan y describen:\n",
    "\n",
    "- **pandas**: Manipulación y análisis de datos estructurados (tablas tipo DataFrame).\n",
    "- **numpy**: Operaciones matemáticas avanzadas y manejo de arreglos multidimensionales.\n",
    "- **matplotlib**: Visualización básica de gráficos e imágenes.\n",
    "- **seaborn**: Visualización estadística avanzada basada en matplotlib.\n",
    "- **opencv-python (cv2)**: Procesamiento de imágenes y visión por computadora.\n",
    "- **scikit-image**: Lectura, filtrado y análisis de imágenes.\n",
    "- **plotly**: Visualización interactiva y dinámica de gráficos.\n",
    "- **kaggle**: Interfaz para descargar datasets desde [Kaggle.com](https://www.kaggle.com).\n",
    "\n",
    "### ⏱ Tiempo estimado de instalación:\n",
    "- Conexión buena: 3 a 7 minutos.\n",
    "- Conexión lenta o Colab recién iniciado: 10 a 15 minutos.\n",
    "\n",
    "### 💡 Recomendación:\n",
    "- Si no va a trabajar directamente con imágenes, puede comentar o eliminar las siguientes librerías:\n",
    "  - `opencv-python`\n",
    "  - `scikit-image`\n",
    "\n",
    "### ⚠️ Importante:\n",
    "- La librería `kaggle` es necesaria solo si va a descargar datasets directamente desde Kaggle.\n",
    "- Asegúrese de haber subido el archivo `kaggle.json` al entorno antes de autenticar con `KaggleApi`.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e96296",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "!pip install -q kaggle\n",
    "!pip install pandas\n",
    "!pip install numpy\n",
    "!pip install matplotlib\n",
    "!pip install seaborn\n",
    "!pip install opencv-python\n",
    "!pip install scikit-image\n",
    "!pip install plotly\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601213dc",
   "metadata": {},
   "source": [
    "### 📥 Importación de librerías necesarias\n",
    "\n",
    "Este bloque importa todas las librerías esenciales que se usarán a lo largo del proyecto. **Puede tardar alrededor de un minuto** en completarse, dependiendo del entorno y los recursos de tu máquina, ya que algunas son pesadas.\n",
    "\n",
    "A continuación se explica el propósito de cada librería:\n",
    "\n",
    "- **`os`**  \n",
    "  Permite interactuar con el sistema operativo. Aquí se usa para cambiar la ubicación en la que `kaggle.json` será buscado (en este caso, la raíz del proyecto).\n",
    "\n",
    "- **`kaggle.api.kaggle_api_extended.KaggleApi`**  \n",
    "  Se utiliza para autenticar y descargar datasets directamente desde [Kaggle](https://www.kaggle.com).\n",
    "\n",
    "- **`pandas` (`pd`)**  \n",
    "  Manejo y análisis de datos en estructuras tipo tabla (`DataFrame`).\n",
    "\n",
    "- **`numpy` (`np`)**  \n",
    "  Cálculo numérico y manejo eficiente de arreglos multidimensionales.\n",
    "\n",
    "- **`shutil`**  \n",
    "  Permite copiar, mover o eliminar archivos y carpetas; útil para organizar las imágenes.\n",
    "\n",
    "- **`cv2` (OpenCV)**  \n",
    "  Librería de visión por computadora para leer, modificar y procesar imágenes.\n",
    "\n",
    "- **`matplotlib.pyplot` (`plt`)**  \n",
    "  Visualización de datos mediante gráficos estáticos y personalizables.\n",
    "\n",
    "- **`seaborn` (`sns`)**  \n",
    "  Complemento de `matplotlib` para gráficos estadísticos más atractivos y fáciles de generar.\n",
    "\n",
    "- **`plotly.graph_objs` (`go`)**  \n",
    "  Generación de gráficos interactivos (por ejemplo, líneas, barras, mapas de calor).\n",
    "\n",
    "- **`skimage.io`**  \n",
    "  Lectura y escritura de imágenes desde archivos o URLs, útil para visualización y análisis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe6ad4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['KAGGLE_CONFIG_DIR'] = os.getcwd()#cambio de la ubicacion de busqueda de el kaggle.json para buscarlo en la raiz del proyecto\n",
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import shutil \n",
    "import cv2 \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from plotly import graph_objs as go\n",
    "from skimage import io\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee45a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "directorio = \"zargazo_dataset\"\n",
    "\n",
    "# Verifica si existe la carpeta para el data set del zargazo, si no la crea\n",
    "if not os.path.exists(directorio):\n",
    "    os.makedirs(directorio)\n",
    "    print(f\"✅ Carpeta creada: {directorio}\")\n",
    "else:\n",
    "    print(f\"ℹ️ La carpeta ya existe: {directorio}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b5ab3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#verifica si el data set ya fue descargado\n",
    "if os.path.exists(directorio) and len(os.listdir(directorio)) > 0:\n",
    "    print(f\"✅ Dataset ya descargado en ./{directorio}.\")\n",
    "else:\n",
    "    print(\"📥 Dataset no encontrado, descargando...\")\n",
    "    api = KaggleApi()\n",
    "    api.authenticate()\n",
    "    api.dataset_download_files(\"sergiogiles/sargacerosds\", path=directorio, unzip=True)\n",
    "    print(f\"✅ Dataset descargado en ./{directorio}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827baeb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ruta_labels = os.path.join(directorio, \"labels\", \"labels.csv\")\n",
    "df_train = pd.read_csv(ruta_labels)\n",
    "datos = df_train.iloc[:,:] # Seleccionar un subconjunto\n",
    "bd_lenght, bd_width = datos.shape\n",
    "datos.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5aa57c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imprimir cuales son las etiquetas únicas\n",
    "print(datos.label.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460791bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "datos.info()\n",
    "print('Tipo de datos de las etiquetas: ', type(datos['label'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6368797",
   "metadata": {},
   "outputs": [],
   "source": [
    "datos.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71dbcfc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#graficos de distriibucion de nivel de sargazo\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "sns.countplot(x='label',data=datos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6896bbd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#graficos de distribucion de las etiquetas de las fotos\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "sns.countplot(x='scene',data=datos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16af039",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imágenes de ejemplo\n",
    "\n",
    "import random\n",
    "\n",
    "idx = random.randint(1, bd_lenght)\n",
    "imagen_ejemplo=io.imread(directorio +\"/images/\"+ str(datos.image_name.iloc[idx]))\n",
    "\n",
    "plt.title(\"Sample image, class=\" + str(datos.label.iloc[idx]))\n",
    "plt.imshow(imagen_ejemplo,vmin=0,vmax=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209778ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para obtener información de la imagen podemos utilizar dtype y shape \n",
    "print('La imagen es de tipo:', imagen_ejemplo.dtype)\n",
    "print(\"Dimensiones de la imagen (high, width, channels):\", imagen_ejemplo.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb0af42",
   "metadata": {},
   "source": [
    "codigo de la red neuronal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7720529c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import io, transform\n",
    "from PIL import Image\n",
    "import time\n",
    "import copy\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torch.autograd import Variable\n",
    "from torchvision import datasets, models, transforms, utils\n",
    "import torch.optim as optim\n",
    "import sklearn\n",
    "import sklearn.model_selection as skl\n",
    "import seaborn as sn\n",
    "%matplotlib inline\n",
    "use_gpu = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Assume that we are on a CUDA machine, then this should print a CUDA device:\n",
    "print(device)\n",
    "print(\"Torch version: \", torch.__version__)\n",
    "print(\"Torchvision version: \", torchvision.__version__)\n",
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8a8d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directorio de la carpeta donde esta el dataset\n",
    "#img_folder = '/kaggle/input/publicsargazods/images'\n",
    "img_folder = os.path.join(\"zargazo_dataset\",\"images\")\n",
    "#csv_file = '/kaggle/input/publicsargazods/labels/labels.csv'\n",
    "csv_file = os.path.join(\"zargazo_dataset\", \"labels\", \"labels.csv\")\n",
    "\n",
    "# Hyper parameters\n",
    "epochs = 5\n",
    "current_epoch = 0\n",
    "batch_size = 32\n",
    "learning_rate = 0.001\n",
    "run_training = True #Si deseamos que el notebook ejecute el entrenamiento\n",
    "model_name = 'resnet' # Red a cargar\n",
    "pretrained = True # True indica que la red se va a inicializar con los parámetros entrenados\n",
    "feature_extract = False #True indica que no se actualizan los parámetros\n",
    "save_weights = True\n",
    "\n",
    "wts_str = 'w_' + model_name + '_pret_' + str(pretrained) + '_feat_' + str(feature_extract) + '_lr_'+ str(learning_rate) \n",
    "print(wts_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc3d501",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SargazoDataset(Dataset):\n",
    "    def __init__(self, dataframe, images_path, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            txt_frame_file (string): Path to the txt files with labels.\n",
    "            images_path (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.sargazo_frame = dataframe\n",
    "        self.root_dir = images_path\n",
    "        self.transform = transform\n",
    "        self.class2id = test_count = {'nada': 0, 'bajo': 1, 'moderado': 2, 'abundante': 3, 'excesivo': 4}\n",
    "        \n",
    "    def pil_loader(self, path):\n",
    "        with open(path, 'rb') as f:\n",
    "            img = Image.open(f)\n",
    "            return img.convert('RGB')\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.sargazo_frame)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        # cuidado si cambia la tabla se debe de cambiar esto\n",
    "        image_path = os.path.join(self.root_dir, self.sargazo_frame.iloc[idx, 0])\n",
    "        \n",
    "        image = self.pil_loader(image_path)\n",
    "        \n",
    "        try: \n",
    "            label = self.sargazo_frame.iloc[idx, 3]\n",
    "        except:\n",
    "            label = 'unknown'\n",
    "\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        sample = (image, self.class2id[label])\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e1152f8",
   "metadata": {},
   "source": [
    "division del conjunto de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba1baeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class2id = test_count = {'nada': 0, 'bajo': 1, 'moderado': 2, 'abundante': 3, 'excesivo': 4}\n",
    "id2class = {0: 'nada', 1: 'bajo', 2: 'moderado', 3: 'abundante', 4: 'excesivo'}\n",
    "num_classes = len(id2class)\n",
    "\n",
    "full_dataset = pd.read_csv(csv_file) \n",
    "full_dataset.sample(5)\n",
    "\n",
    "#print(full_dataset.iloc[0, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e8aec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_labels = 'label'\n",
    "random = 46 # for reproducible experiments\n",
    "\n",
    "# Aqui se divide el conjunto de datos\n",
    "train_df, valid_df = skl.train_test_split(full_dataset, test_size = 0.2, stratify = full_dataset[col_labels], random_state = random)\n",
    "\n",
    "training_dataset = SargazoDataset(train_df, img_folder)\n",
    "test_dataset = SargazoDataset(valid_df, img_folder)\n",
    "\n",
    "print(\"Número de ejemplos:\", len(training_dataset))\n",
    "\n",
    "def show_image(image, label):\n",
    "    plt.imshow(image, cmap = 'gray')\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc06d0e8",
   "metadata": {},
   "source": [
    "mostrar ejemplos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dafc1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "\n",
    "for i in range(len(training_dataset)):\n",
    "    sample = training_dataset[i]\n",
    "    print(sample)\n",
    "    image, label = sample\n",
    "    \n",
    "    ax = plt.subplot(1, 4, i + 1)\n",
    "    plt.tight_layout()\n",
    "    ax.set_title('Sample #{} Class {}'.format(i, id2class[label]))\n",
    "    ax.axis('off')\n",
    "    show_image(image, label)\n",
    "\n",
    "    if i == 3:\n",
    "        plt.show()\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a02b7c9",
   "metadata": {},
   "source": [
    "descenso por gradiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b866c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloaders, criterion, optimizer, num_epochs = 25, is_inception= False, save_after = 100):\n",
    "    since = time.time()\n",
    "    \n",
    "    val_acc_history = []\n",
    "    train_acc_history = []\n",
    "    val_loss_history = []\n",
    "    train_loss_history = []\n",
    "    \n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    \n",
    "    #print(device)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs -1))\n",
    "        \n",
    "        #Each epoch as a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            \n",
    "            # Iterate over data\n",
    "            for inputs, labels in iter(dataloaders[phase]):\n",
    "                #print(inputs)\n",
    "                #print(labels)\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                \n",
    "                #zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                #forward\n",
    "                # track history\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    \n",
    "                    if is_inception and phase == 'train':\n",
    "                        outputs, aux_outputs = model(inputs)\n",
    "                        loss1 = criterion(outputs, labels)\n",
    "                        loss2 = criterion(aux_outputs, labels)\n",
    "                        loss = loss1 + 0.4*loss2\n",
    "                        \n",
    "                    else:\n",
    "                        outputs = model(inputs)\n",
    "                        loss = criterion(outputs, labels)\n",
    "                        \n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    \n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                #statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "                \n",
    "            epoch_loss = running_loss /len(dataloaders[phase].dataset)\n",
    "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
    "            \n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "            \n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                torch.save(model.state_dict(), wts_str + '_best.pt')\n",
    "            if phase == 'val':\n",
    "                val_acc_history.append(epoch_acc)\n",
    "                val_loss_history.append(epoch_loss)\n",
    "            else:\n",
    "                train_acc_history.append(epoch_acc)\n",
    "                train_loss_history.append(epoch_loss)\n",
    "            \n",
    "            if phase == 'train' and epoch % save_after == 0 :\n",
    "                torch.save(model.state_dict(), wts_str + '_epoch' + str(epoch) + '.pt')\n",
    "        print()\n",
    "        \n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:.4f}'.format(best_acc))\n",
    "    \n",
    "    #load the best model\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, val_acc_history, train_acc_history, val_loss_history, train_loss_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8acb0cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set model parameters\n",
    "def set_parameter_requires_grad(model, feature_extracting):\n",
    "    if feature_extracting:\n",
    "        for param in model.parameters():\n",
    "            # Freeze parameters\n",
    "            param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea54a02",
   "metadata": {},
   "source": [
    "crear modelo de red neuronal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3dfd04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and reshape the networks\n",
    "def initialize_model(model_name, num_classes, feature_extract, use_pretrained=True):\n",
    "    # Initialize these variables which will be set in this if statement. Each of these\n",
    "    #   variables is model specific.\n",
    "    model_ft = None\n",
    "    input_size = 0\n",
    "\n",
    "    if model_name == \"resnet\":\n",
    "        \"\"\" Resnet18\n",
    "        \"\"\"\n",
    "        model_ft = models.resnet18(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"alexnet\":\n",
    "        \"\"\" Alexnet\n",
    "        \"\"\"\n",
    "        model_ft = models.alexnet(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier[6].in_features\n",
    "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"vgg\":\n",
    "        \"\"\" VGG16\n",
    "        \"\"\"\n",
    "        model_ft = models.vgg16(pretrained=use_pretrained)\n",
    "        #model_ft = models.vgg16(weights='IMAGENET1K_V1')\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier[6].in_features\n",
    "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"squeezenet\":\n",
    "        \"\"\" Squeezenet\n",
    "        \"\"\"\n",
    "        model_ft = models.squeezenet1_0(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        model_ft.classifier[1] = nn.Conv2d(512, num_classes, kernel_size=(1,1), stride=(1,1))\n",
    "        model_ft.num_classes = num_classes\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"densenet\":\n",
    "        \"\"\" Densenet\n",
    "        \"\"\"\n",
    "        model_ft = models.densenet121(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier.in_features\n",
    "        model_ft.classifier = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"inception\":\n",
    "        \"\"\" Inception v3\n",
    "        Be careful, expects (299,299) sized images and has auxiliary output\n",
    "        \"\"\"\n",
    "        model_ft = models.inception_v3(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        # Handle the auxilary net\n",
    "        num_ftrs = model_ft.AuxLogits.fc.in_features\n",
    "        model_ft.AuxLogits.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        # Handle the primary net\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 299\n",
    "\n",
    "    else:\n",
    "        print(\"Invalid model name, exiting...\")\n",
    "        exit()\n",
    "\n",
    "    return model_ft, input_size\n",
    "\n",
    "# Initialize the model for this run\n",
    "model_ft, input_size = initialize_model(model_name, num_classes, feature_extract, use_pretrained=pretrained)\n",
    "\n",
    "# Print the model we just instantiated\n",
    "print(model_ft)\n",
    "\n",
    "model_ft.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d6a3a4",
   "metadata": {},
   "source": [
    "empieza el entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6271a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation and normalization for training\n",
    "# Just normalization for validation\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(input_size),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(input_size),\n",
    "        transforms.CenterCrop(input_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e924bb16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# configure paths to the description txt file and the images folder\n",
    "#images_path = '../input/sargazo-dataset/sargazo_dataset/images'\n",
    "\n",
    "# Create training and validation datasets\n",
    "image_datasets = {'train': SargazoDataset(train_df, img_folder, data_transforms['train']), 'val': SargazoDataset(valid_df, img_folder, data_transforms['val'])}\n",
    "# Create training and validation dataloaders\n",
    "dataloaders_dict = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size, shuffle=True, num_workers=4) for x in ['train', 'val']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a579999",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the optimizer\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "params_to_update = model_ft.parameters()\n",
    "print(\"Params to learn\")\n",
    "\n",
    "if feature_extract:\n",
    "    params_to_update = []\n",
    "    for name, param in model_ft.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            params_to_update.append(param)\n",
    "            print(\"\\t\", name)\n",
    "else:\n",
    "    for name, param in model_ft.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            print(\"\\t\", name)\n",
    "            \n",
    "optimizer_ft = optim.SGD(params_to_update, lr=learning_rate,momentum=0.9)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00e8308",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute full training\n",
    "if run_training:\n",
    "    model_ft, hist, hist_t,loss_hist,loss_hist_t = train_model(model_ft, dataloaders_dict, criterion, optimizer_ft, num_epochs = epochs, is_inception=(model_name==\"inception\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d731fae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if save_weights:\n",
    "    torch.save(model_ft.state_dict(), wts_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd9b133",
   "metadata": {},
   "source": [
    "graficar resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100c5be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the training curves of validation accuracy vs. number\n",
    "#  of training epochs for the transfer learning method and\n",
    "#  the model trained from scratch\n",
    "vhist = []\n",
    "thist = []\n",
    "\n",
    "vhist = [h.cpu().numpy() for h in hist]\n",
    "thist = [h.cpu().numpy() for h in hist_t]\n",
    "#shist = [h.cpu().numpy() for h in scratch_hist]\n",
    "\n",
    "np.save('val_history', vhist)\n",
    "np.save('train_history', vhist)\n",
    "\n",
    "plt.title(\"Validation Accuracy vs. Number of Training Epochs\")\n",
    "plt.xlabel(\"Training Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.plot(range(1,epochs+1),thist,label=\"Training\")\n",
    "plt.plot(range(1,epochs+1),vhist,label=\"Validation\")\n",
    "plt.ylim((0,1.))\n",
    "plt.xticks(np.arange(1, epochs+1, 1.0))\n",
    "plt.legend()\n",
    "file_name = wts_str + '_acc.png'\n",
    "plt.savefig(file_name)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd62ab70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the training curves of validation accuracy vs. number\n",
    "#  of training epochs for the transfer learning method and\n",
    "#  the model trained from scratch\n",
    "vhist_loss = np.array(loss_hist)\n",
    "thist_loss = np.array(loss_hist_t)\n",
    "\n",
    "np.save('val_history', vhist_loss)\n",
    "np.save('train_history', thist_loss)\n",
    "\n",
    "plt.title(\"Validation Loss vs. Number of Training Epochs\")\n",
    "plt.xlabel(\"Training Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.plot(range(1,epochs+1),thist_loss,label=\"Training\")\n",
    "plt.plot(range(1,epochs+1),vhist_loss,label=\"Validation\")\n",
    "plt.ylim((0,4.))\n",
    "plt.xticks(np.arange(1, epochs+1, 1.0))\n",
    "plt.legend()\n",
    "file_name = wts_str + '_loss.png'\n",
    "plt.savefig(file_name)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3290c54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, dataloaders):\n",
    "    print(\"Evaluating model\")\n",
    "    print(time.time())\n",
    "            \n",
    "    # Iterate over data\n",
    "    it = 0\n",
    "    for inputs, labels in dataloaders['val']:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "                \n",
    "        model.train(False)\n",
    "        model.eval()\n",
    "                    \n",
    "        outputs = model(inputs)\n",
    "                        \n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        \n",
    "        np_pred_labels = preds.cpu().numpy()\n",
    "        np_real_labels = labels.cpu().numpy()\n",
    "        if it == 0:\n",
    "            pred_labels = np_pred_labels\n",
    "            real_labels = np_real_labels\n",
    "        else:\n",
    "            pred_labels = np.concatenate((pred_labels,np_pred_labels))\n",
    "            real_labels = np.concatenate((real_labels,np_real_labels))\n",
    "        it= it+1\n",
    "        \n",
    "        del inputs\n",
    "        del labels\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    print(time.time())\n",
    "    return pred_labels,real_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986ce074",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_labels,actual_labels = test_model(model_ft, dataloaders_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03db1df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(actual_labels,predict_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56efc15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_confusion = pd.crosstab(actual_labels, predict_labels,rownames=[\"True label\"],colnames=[\"Predicted label\"])\n",
    "print(df_confusion)\n",
    "df_confusion.rename(columns=id2class,index=id2class,inplace=True)\n",
    "print(df_confusion)\n",
    "df_confusion.to_csv('cm_exp5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe243fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(9,6))\n",
    "\n",
    "parameters = {'axes.labelsize': 10}\n",
    "plt.rcParams.update(parameters)\n",
    "\n",
    "g = sn.heatmap(df_confusion, annot = True, cmap = 'Blues',ax=ax)\n",
    "g.set_xticklabels(g.get_xticklabels(), rotation=45, horizontalalignment='right')\n",
    "g.set_yticklabels(g.get_yticklabels(), rotation=0, horizontalalignment='right')\n",
    "\n",
    "plt.savefig(\"CM_exp5.eps\",format = \"eps\",bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27b3967",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_norm_col= round(df_confusion.div(df_confusion.sum(axis=1),axis=0),2) \n",
    "print(df_norm_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aeedc2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(9,6))\n",
    "\n",
    "parameters = {'axes.labelsize': 10}\n",
    "plt.rcParams.update(parameters)\n",
    "\n",
    "g = sn.heatmap(df_norm_col, annot = True, cmap = 'Blues')\n",
    "g.set_xticklabels(g.get_xticklabels(), rotation=45, horizontalalignment='right')\n",
    "g.set_yticklabels(g.get_yticklabels(), rotation=0, horizontalalignment='right')\n",
    "\n",
    "plt.savefig(\"CM_exp5_norm.eps\",format = \"eps\",bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a67badc8",
   "metadata": {},
   "source": [
    "inferencia para el challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9aed5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_file = '/kaggle/input/publicsargazods/labels/test.csv'\n",
    "test_file = os.path.join(\"zargazo_dataset\", \"labels\", \"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aeed4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(test_file) \n",
    "test_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714acfdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pil_loader(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        img = Image.open(f)\n",
    "        return img.convert('RGB')\n",
    "\n",
    "    \n",
    "model_ft.eval()\n",
    "test_predictions = []\n",
    "for file in test_df['image_name']:\n",
    "    \n",
    "    # cuidado si cambia la tabla se debe de cambiar esto\n",
    "    image_path = os.path.join(img_folder, file)\n",
    "    #print(image_path)\n",
    "    \n",
    "    image = pil_loader(image_path)\n",
    "    img_transf = data_transforms['val'](image)\n",
    "    img_transf = img_transf.unsqueeze(0)\n",
    "    #print(img_transf.shape)\n",
    "    \n",
    "    #print(labels)\n",
    "    img_transf = img_transf.to(device)\n",
    "                       \n",
    "    outputs = model_ft(img_transf)\n",
    "    #print(outputs)                    \n",
    "    _, preds = torch.max(outputs, 1)\n",
    "    test_predictions.append(id2class[preds.cpu().numpy()[0]])\n",
    "    \n",
    "#print(test_predictions)\n",
    "temp = {'image_name': test_df['image_name'], 'label': test_predictions}\n",
    "output_df = pd.DataFrame(data=temp)\n",
    "output_df.sample(10)\n",
    "\n",
    "output_df.to_csv('outputs.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e13da7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
