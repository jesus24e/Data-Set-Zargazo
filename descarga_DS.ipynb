{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "988687fd",
   "metadata": {},
   "source": [
    "# üì¶ Instalaci√≥n de Librer√≠as Necesarias para el Proyecto\n",
    "\n",
    "Este proyecto requiere varias bibliotecas para el an√°lisis y procesamiento de datos e im√°genes. A continuaci√≥n, se listan y describen:\n",
    "\n",
    "- **pandas**: Manipulaci√≥n y an√°lisis de datos estructurados (tablas tipo DataFrame).\n",
    "- **numpy**: Operaciones matem√°ticas avanzadas y manejo de arreglos multidimensionales.\n",
    "- **matplotlib**: Visualizaci√≥n b√°sica de gr√°ficos e im√°genes.\n",
    "- **seaborn**: Visualizaci√≥n estad√≠stica avanzada basada en matplotlib.\n",
    "- **opencv-python (cv2)**: Procesamiento de im√°genes y visi√≥n por computadora.\n",
    "- **scikit-image**: Lectura, filtrado y an√°lisis de im√°genes.\n",
    "- **plotly**: Visualizaci√≥n interactiva y din√°mica de gr√°ficos.\n",
    "- **kaggle**: Interfaz para descargar datasets desde [Kaggle.com](https://www.kaggle.com).\n",
    "\n",
    "### ‚è± Tiempo estimado de instalaci√≥n:\n",
    "- Conexi√≥n buena: 3 a 7 minutos.\n",
    "- Conexi√≥n lenta o Colab reci√©n iniciado: 10 a 15 minutos.\n",
    "\n",
    "### üí° Recomendaci√≥n:\n",
    "- Si no va a trabajar directamente con im√°genes, puede comentar o eliminar las siguientes librer√≠as:\n",
    "  - `opencv-python`\n",
    "  - `scikit-image`\n",
    "\n",
    "### ‚ö†Ô∏è Importante:\n",
    "- La librer√≠a `kaggle` es necesaria solo si va a descargar datasets directamente desde Kaggle.\n",
    "- Aseg√∫rese de haber subido el archivo `kaggle.json` al entorno antes de autenticar con `KaggleApi`.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e96296",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "!pip install -q kaggle\n",
    "!pip install pandas\n",
    "!pip install numpy\n",
    "!pip install matplotlib\n",
    "!pip install seaborn\n",
    "!pip install opencv-python\n",
    "!pip install scikit-image\n",
    "!pip install plotly\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601213dc",
   "metadata": {},
   "source": [
    "### üì• Importaci√≥n de librer√≠as necesarias\n",
    "\n",
    "Este bloque importa todas las librer√≠as esenciales que se usar√°n a lo largo del proyecto. **Puede tardar alrededor de un minuto** en completarse, dependiendo del entorno y los recursos de tu m√°quina, ya que algunas son pesadas.\n",
    "\n",
    "A continuaci√≥n se explica el prop√≥sito de cada librer√≠a:\n",
    "\n",
    "- **`os`**  \n",
    "  Permite interactuar con el sistema operativo. Aqu√≠ se usa para cambiar la ubicaci√≥n en la que `kaggle.json` ser√° buscado (en este caso, la ra√≠z del proyecto).\n",
    "\n",
    "- **`kaggle.api.kaggle_api_extended.KaggleApi`**  \n",
    "  Se utiliza para autenticar y descargar datasets directamente desde [Kaggle](https://www.kaggle.com).\n",
    "\n",
    "- **`pandas` (`pd`)**  \n",
    "  Manejo y an√°lisis de datos en estructuras tipo tabla (`DataFrame`).\n",
    "\n",
    "- **`numpy` (`np`)**  \n",
    "  C√°lculo num√©rico y manejo eficiente de arreglos multidimensionales.\n",
    "\n",
    "- **`shutil`**  \n",
    "  Permite copiar, mover o eliminar archivos y carpetas; √∫til para organizar las im√°genes.\n",
    "\n",
    "- **`cv2` (OpenCV)**  \n",
    "  Librer√≠a de visi√≥n por computadora para leer, modificar y procesar im√°genes.\n",
    "\n",
    "- **`matplotlib.pyplot` (`plt`)**  \n",
    "  Visualizaci√≥n de datos mediante gr√°ficos est√°ticos y personalizables.\n",
    "\n",
    "- **`seaborn` (`sns`)**  \n",
    "  Complemento de `matplotlib` para gr√°ficos estad√≠sticos m√°s atractivos y f√°ciles de generar.\n",
    "\n",
    "- **`plotly.graph_objs` (`go`)**  \n",
    "  Generaci√≥n de gr√°ficos interactivos (por ejemplo, l√≠neas, barras, mapas de calor).\n",
    "\n",
    "- **`skimage.io`**  \n",
    "  Lectura y escritura de im√°genes desde archivos o URLs, √∫til para visualizaci√≥n y an√°lisis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe6ad4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['KAGGLE_CONFIG_DIR'] = os.getcwd()#cambio de la ubicacion de busqueda de el kaggle.json para buscarlo en la raiz del proyecto\n",
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import shutil \n",
    "import cv2 \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from plotly import graph_objs as go\n",
    "from skimage import io\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee45a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "directorio = \"zargazo_dataset\"\n",
    "\n",
    "# Verifica si existe la carpeta para el data set del zargazo, si no la crea\n",
    "if not os.path.exists(directorio):\n",
    "    os.makedirs(directorio)\n",
    "    print(f\"‚úÖ Carpeta creada: {directorio}\")\n",
    "else:\n",
    "    print(f\"‚ÑπÔ∏è La carpeta ya existe: {directorio}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b5ab3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#verifica si el data set ya fue descargado\n",
    "if os.path.exists(directorio) and len(os.listdir(directorio)) > 0:\n",
    "    print(f\"‚úÖ Dataset ya descargado en ./{directorio}.\")\n",
    "else:\n",
    "    print(\"üì• Dataset no encontrado, descargando...\")\n",
    "    api = KaggleApi()\n",
    "    api.authenticate()\n",
    "    api.dataset_download_files(\"irvingvasquez/publicsargazods\", path=directorio, unzip=True)\n",
    "    print(f\"‚úÖ Dataset descargado en ./{directorio}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827baeb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ruta_labels = os.path.join(directorio, \"labels\", \"labels.csv\")\n",
    "df_train = pd.read_csv(ruta_labels)\n",
    "datos = df_train.iloc[:,:] # Seleccionar un subconjunto\n",
    "bd_lenght, bd_width = datos.shape\n",
    "datos.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5aa57c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imprimir cuales son las etiquetas √∫nicas\n",
    "print(datos.label.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460791bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "datos.info()\n",
    "print('Tipo de datos de las etiquetas: ', type(datos['label'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6368797",
   "metadata": {},
   "outputs": [],
   "source": [
    "datos.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71dbcfc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#graficos de distriibucion de nivel de sargazo\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "sns.countplot(x='label',data=datos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6896bbd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#graficos de distribucion de las etiquetas de las fotos\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "sns.countplot(x='scene',data=datos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16af039",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Im√°genes de ejemplo\n",
    "\n",
    "import random\n",
    "\n",
    "idx = random.randint(1, bd_lenght)\n",
    "imagen_ejemplo=io.imread(directorio +\"/images/\"+ str(datos.image_name.iloc[idx]))\n",
    "\n",
    "plt.title(\"Sample image, class=\" + str(datos.label.iloc[idx]))\n",
    "plt.imshow(imagen_ejemplo,vmin=0,vmax=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209778ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para obtener informaci√≥n de la imagen podemos utilizar dtype y shape \n",
    "print('La imagen es de tipo:', imagen_ejemplo.dtype)\n",
    "print(\"Dimensiones de la imagen (high, width, channels):\", imagen_ejemplo.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc03746d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#instalacion de librerias para red neuronal\n",
    "\n",
    "!pip install scikit-learn\n",
    "!pip install torch torchvision\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa87b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#librerias para la red neuronal\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809cf9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = os.path.join(\"zargazo_dataset\",\"images\")\n",
    "CSV_PATH = os.path.join(\"zargazo_dataset\", \"labels\", \"labels.csv\")\n",
    "IMG_SIZE = 64\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5cd02e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(CSV_PATH)\n",
    "\n",
    "# Usar solo columnas necesarias\n",
    "df = df[['image_name', 'label']]\n",
    "\n",
    "# Mapear etiquetas a n√∫meros\n",
    "labels = df['label'].unique()\n",
    "label2idx = {label: idx for idx, label in enumerate(labels)}\n",
    "idx2label = {v: k for k, v in label2idx.items()}\n",
    "df['label_idx'] = df['label'].map(label2idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31d2ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, val_df = train_test_split(df, test_size=0.2, stratify=df['label_idx'], random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5220ac7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SargazoDataset(Dataset):\n",
    "    def __init__(self, df, img_dir, transform=None):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.df.loc[idx, 'image_name'])\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        label = self.df.loc[idx, 'label_idx']\n",
    "        return image, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272742fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "train_dataset = SargazoDataset(train_df, DATASET_PATH, transform)\n",
    "val_dataset = SargazoDataset(val_df, DATASET_PATH, transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7efff1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32, 64, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2),\n",
    "            nn.Conv2d(64, 128, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128 * (IMG_SIZE//8) * (IMG_SIZE//8), 128), nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb701e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "#empezar entrenamiento\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = SimpleCNN(num_classes=len(label2idx)).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS}, Loss: {running_loss/len(train_loader):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94abf084",
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluacion\n",
    "\n",
    "model.eval()\n",
    "y_true, y_pred = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in val_loader:\n",
    "        images = images.to(device)\n",
    "        outputs = model(images)\n",
    "        preds = outputs.argmax(dim=1).cpu().numpy()\n",
    "        y_pred.extend(preds)\n",
    "        y_true.extend(labels.numpy())\n",
    "\n",
    "target_names = [idx2label[i] for i in sorted(idx2label.keys())]\n",
    "print(classification_report(y_true, y_pred, target_names=target_names))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea782f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHECKPOINT = \"modelo_sargazo.pth\"\n",
    "torch.save(model.state_dict(), CHECKPOINT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d225a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "# Ruta destino, por ejemplo: Drive o carpeta personalizada\n",
    "CHECKPOINT_DRIVE_DIR = Path(\"checkpoints_guardados\")  # Cambia esto seg√∫n tu caso\n",
    "\n",
    "# Crear carpeta si no existe\n",
    "CHECKPOINT_DRIVE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Copiar archivo\n",
    "destination_path = CHECKPOINT_DRIVE_DIR / CHECKPOINT\n",
    "shutil.copy(CHECKPOINT, destination_path)\n",
    "\n",
    "print(f\"Checkpoint copied to {destination_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9d6d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(destination_path))\n",
    "model.to(device)\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aadfb594",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------- TEST EVALUATION ----------------------\n",
    "\n",
    "# Asegurarse de que el modelo est√° en modo evaluaci√≥n\n",
    "model.eval()\n",
    "\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "all_images = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x_batch, y_batch in val_loader:\n",
    "        x_batch = x_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "\n",
    "        # Forward pass (logits)\n",
    "        logits = model(x_batch)\n",
    "\n",
    "        # Predicciones usando argmax\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "\n",
    "        # Guardar resultados en CPU\n",
    "        all_preds.append(preds.cpu())\n",
    "        all_labels.append(y_batch.cpu())\n",
    "        all_images.append(x_batch.cpu())\n",
    "\n",
    "# Concatenar todos los batches\n",
    "all_preds = torch.cat(all_preds).numpy()\n",
    "all_labels = torch.cat(all_labels).numpy()\n",
    "all_images = torch.cat(all_images)\n",
    "\n",
    "# Evaluar desempe√±o\n",
    "matches = all_preds == all_labels\n",
    "right_preds = np.sum(matches)\n",
    "wrong_preds = len(all_labels) - right_preds\n",
    "\n",
    "# Mostrar m√©tricas\n",
    "print(f\"\\n‚úÖ Test set results:\")\n",
    "print(f\"  - Predicciones correctas: {right_preds} de {len(all_labels)}\")\n",
    "print(f\"  - Predicciones incorrectas: {wrong_preds}\")\n",
    "print(f\"  - Accuracy: {right_preds / len(all_labels):.2%}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
