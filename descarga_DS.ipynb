{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "988687fd",
   "metadata": {},
   "source": [
    "# 📦 Instalación de Librerías Necesarias para el Proyecto\n",
    "\n",
    "Este proyecto requiere varias bibliotecas para el análisis y procesamiento de datos e imágenes. A continuación, se listan y describen:\n",
    "\n",
    "- **pandas**: Manipulación y análisis de datos estructurados (tablas tipo DataFrame).\n",
    "- **numpy**: Operaciones matemáticas avanzadas y manejo de arreglos multidimensionales.\n",
    "- **matplotlib**: Visualización básica de gráficos e imágenes.\n",
    "- **seaborn**: Visualización estadística avanzada basada en matplotlib.\n",
    "- **opencv-python (cv2)**: Procesamiento de imágenes y visión por computadora.\n",
    "- **scikit-image**: Lectura, filtrado y análisis de imágenes.\n",
    "- **plotly**: Visualización interactiva y dinámica de gráficos.\n",
    "- **kaggle**: Interfaz para descargar datasets desde [Kaggle.com](https://www.kaggle.com).\n",
    "\n",
    "### ⏱ Tiempo estimado de instalación:\n",
    "- Conexión buena: 3 a 7 minutos.\n",
    "- Conexión lenta o Colab recién iniciado: 10 a 15 minutos.\n",
    "\n",
    "### 💡 Recomendación:\n",
    "- Si no va a trabajar directamente con imágenes, puede comentar o eliminar las siguientes librerías:\n",
    "  - `opencv-python`\n",
    "  - `scikit-image`\n",
    "\n",
    "### ⚠️ Importante:\n",
    "- La librería `kaggle` es necesaria solo si va a descargar datasets directamente desde Kaggle.\n",
    "- Asegúrese de haber subido el archivo `kaggle.json` al entorno antes de autenticar con `KaggleApi`.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e96296",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "!pip install -q kaggle\n",
    "!pip install pandas\n",
    "!pip install numpy\n",
    "!pip install matplotlib\n",
    "!pip install seaborn\n",
    "!pip install opencv-python\n",
    "!pip install scikit-image\n",
    "!pip install plotly\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601213dc",
   "metadata": {},
   "source": [
    "### 📥 Importación de librerías necesarias\n",
    "\n",
    "Este bloque importa todas las librerías esenciales que se usarán a lo largo del proyecto. **Puede tardar alrededor de un minuto** en completarse, dependiendo del entorno y los recursos de tu máquina, ya que algunas son pesadas.\n",
    "\n",
    "A continuación se explica el propósito de cada librería:\n",
    "\n",
    "- **`os`**  \n",
    "  Permite interactuar con el sistema operativo. Aquí se usa para cambiar la ubicación en la que `kaggle.json` será buscado (en este caso, la raíz del proyecto).\n",
    "\n",
    "- **`kaggle.api.kaggle_api_extended.KaggleApi`**  \n",
    "  Se utiliza para autenticar y descargar datasets directamente desde [Kaggle](https://www.kaggle.com).\n",
    "\n",
    "- **`pandas` (`pd`)**  \n",
    "  Manejo y análisis de datos en estructuras tipo tabla (`DataFrame`).\n",
    "\n",
    "- **`numpy` (`np`)**  \n",
    "  Cálculo numérico y manejo eficiente de arreglos multidimensionales.\n",
    "\n",
    "- **`shutil`**  \n",
    "  Permite copiar, mover o eliminar archivos y carpetas; útil para organizar las imágenes.\n",
    "\n",
    "- **`cv2` (OpenCV)**  \n",
    "  Librería de visión por computadora para leer, modificar y procesar imágenes.\n",
    "\n",
    "- **`matplotlib.pyplot` (`plt`)**  \n",
    "  Visualización de datos mediante gráficos estáticos y personalizables.\n",
    "\n",
    "- **`seaborn` (`sns`)**  \n",
    "  Complemento de `matplotlib` para gráficos estadísticos más atractivos y fáciles de generar.\n",
    "\n",
    "- **`plotly.graph_objs` (`go`)**  \n",
    "  Generación de gráficos interactivos (por ejemplo, líneas, barras, mapas de calor).\n",
    "\n",
    "- **`skimage.io`**  \n",
    "  Lectura y escritura de imágenes desde archivos o URLs, útil para visualización y análisis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe6ad4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['KAGGLE_CONFIG_DIR'] = os.getcwd()#cambio de la ubicacion de busqueda de el kaggle.json para buscarlo en la raiz del proyecto\n",
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import shutil \n",
    "import cv2 \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from plotly import graph_objs as go\n",
    "from skimage import io\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee45a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "directorio = \"zargazo_dataset\"\n",
    "\n",
    "# Verifica si existe la carpeta para el data set del zargazo, si no la crea\n",
    "if not os.path.exists(directorio):\n",
    "    os.makedirs(directorio)\n",
    "    print(f\"✅ Carpeta creada: {directorio}\")\n",
    "else:\n",
    "    print(f\"ℹ️ La carpeta ya existe: {directorio}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b5ab3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#verifica si el data set ya fue descargado\n",
    "if os.path.exists(directorio) and len(os.listdir(directorio)) > 0:\n",
    "    print(f\"✅ Dataset ya descargado en ./{directorio}.\")\n",
    "else:\n",
    "    print(\"📥 Dataset no encontrado, descargando...\")\n",
    "    api = KaggleApi()\n",
    "    api.authenticate()\n",
    "    api.dataset_download_files(\"irvingvasquez/publicsargazods\", path=directorio, unzip=True)\n",
    "    print(f\"✅ Dataset descargado en ./{directorio}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827baeb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ruta_labels = os.path.join(directorio, \"labels\", \"labels.csv\")\n",
    "df_train = pd.read_csv(ruta_labels)\n",
    "datos = df_train.iloc[:,:] # Seleccionar un subconjunto\n",
    "bd_lenght, bd_width = datos.shape\n",
    "datos.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5aa57c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imprimir cuales son las etiquetas únicas\n",
    "print(datos.label.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460791bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "datos.info()\n",
    "print('Tipo de datos de las etiquetas: ', type(datos['label'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6368797",
   "metadata": {},
   "outputs": [],
   "source": [
    "datos.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71dbcfc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#graficos de distriibucion de nivel de sargazo\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "sns.countplot(x='label',data=datos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6896bbd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#graficos de distribucion de las etiquetas de las fotos\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "sns.countplot(x='scene',data=datos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16af039",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imágenes de ejemplo\n",
    "\n",
    "import random\n",
    "\n",
    "idx = random.randint(1, bd_lenght)\n",
    "imagen_ejemplo=io.imread(directorio +\"/images/\"+ str(datos.image_name.iloc[idx]))\n",
    "\n",
    "plt.title(\"Sample image, class=\" + str(datos.label.iloc[idx]))\n",
    "plt.imshow(imagen_ejemplo,vmin=0,vmax=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209778ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para obtener información de la imagen podemos utilizar dtype y shape \n",
    "print('La imagen es de tipo:', imagen_ejemplo.dtype)\n",
    "print(\"Dimensiones de la imagen (high, width, channels):\", imagen_ejemplo.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc03746d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#instalacion de librerias para red neuronal\n",
    "\n",
    "!pip install scikit-learn\n",
    "!pip install torch torchvision\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa87b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#librerias para la red neuronal\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809cf9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = os.path.join(\"zargazo_dataset\",\"images\")\n",
    "CSV_PATH = os.path.join(\"zargazo_dataset\", \"labels\", \"labels.csv\")\n",
    "IMG_SIZE = 64\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5cd02e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(CSV_PATH)\n",
    "\n",
    "# Usar solo columnas necesarias\n",
    "df = df[['image_name', 'label']]\n",
    "\n",
    "# Mapear etiquetas a números\n",
    "labels = df['label'].unique()\n",
    "label2idx = {label: idx for idx, label in enumerate(labels)}\n",
    "idx2label = {v: k for k, v in label2idx.items()}\n",
    "df['label_idx'] = df['label'].map(label2idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31d2ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, val_df = train_test_split(df, test_size=0.2, stratify=df['label_idx'], random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5220ac7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SargazoDataset(Dataset):\n",
    "    def __init__(self, df, img_dir, transform=None):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.df.loc[idx, 'image_name'])\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        label = self.df.loc[idx, 'label_idx']\n",
    "        return image, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272742fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "train_dataset = SargazoDataset(train_df, DATASET_PATH, transform)\n",
    "val_dataset = SargazoDataset(val_df, DATASET_PATH, transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7efff1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32, 64, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2),\n",
    "            nn.Conv2d(64, 128, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128 * (IMG_SIZE//8) * (IMG_SIZE//8), 128), nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb701e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "#empezar entrenamiento\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = SimpleCNN(num_classes=len(label2idx)).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS}, Loss: {running_loss/len(train_loader):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94abf084",
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluacion\n",
    "\n",
    "model.eval()\n",
    "y_true, y_pred = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in val_loader:\n",
    "        images = images.to(device)\n",
    "        outputs = model(images)\n",
    "        preds = outputs.argmax(dim=1).cpu().numpy()\n",
    "        y_pred.extend(preds)\n",
    "        y_true.extend(labels.numpy())\n",
    "\n",
    "target_names = [idx2label[i] for i in sorted(idx2label.keys())]\n",
    "print(classification_report(y_true, y_pred, target_names=target_names))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea782f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHECKPOINT = \"modelo_sargazo.pth\"\n",
    "torch.save(model.state_dict(), CHECKPOINT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d225a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "# Ruta destino, por ejemplo: Drive o carpeta personalizada\n",
    "CHECKPOINT_DRIVE_DIR = Path(\"checkpoints_guardados\")  # Cambia esto según tu caso\n",
    "\n",
    "# Crear carpeta si no existe\n",
    "CHECKPOINT_DRIVE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Copiar archivo\n",
    "destination_path = CHECKPOINT_DRIVE_DIR / CHECKPOINT\n",
    "shutil.copy(CHECKPOINT, destination_path)\n",
    "\n",
    "print(f\"Checkpoint copied to {destination_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9d6d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(destination_path))\n",
    "model.to(device)\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aadfb594",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------- TEST EVALUATION ----------------------\n",
    "\n",
    "# Asegurarse de que el modelo está en modo evaluación\n",
    "model.eval()\n",
    "\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "all_images = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x_batch, y_batch in val_loader:\n",
    "        x_batch = x_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "\n",
    "        # Forward pass (logits)\n",
    "        logits = model(x_batch)\n",
    "\n",
    "        # Predicciones usando argmax\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "\n",
    "        # Guardar resultados en CPU\n",
    "        all_preds.append(preds.cpu())\n",
    "        all_labels.append(y_batch.cpu())\n",
    "        all_images.append(x_batch.cpu())\n",
    "\n",
    "# Concatenar todos los batches\n",
    "all_preds = torch.cat(all_preds).numpy()\n",
    "all_labels = torch.cat(all_labels).numpy()\n",
    "all_images = torch.cat(all_images)\n",
    "\n",
    "# Evaluar desempeño\n",
    "matches = all_preds == all_labels\n",
    "right_preds = np.sum(matches)\n",
    "wrong_preds = len(all_labels) - right_preds\n",
    "\n",
    "# Mostrar métricas\n",
    "print(f\"\\n✅ Test set results:\")\n",
    "print(f\"  - Predicciones correctas: {right_preds} de {len(all_labels)}\")\n",
    "print(f\"  - Predicciones incorrectas: {wrong_preds}\")\n",
    "print(f\"  - Accuracy: {right_preds / len(all_labels):.2%}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
